{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db4c858",
   "metadata": {},
   "source": [
    "# SVM (RAPIDS cuML GPU-Accelerated) on GPU2 Features\n",
    "\n",
    "This notebook trains an SVM classifier using **RAPIDS cuML** (GPU-accelerated SVM) with RBF kernel (`C=10`, `gamma='auto'`) on features extracted by the GPU2 autoencoder, then evaluates performance.\n",
    "\n",
    "**‚ö° GPU-ACCELERATED: RAPIDS cuML SVM trains on GPU (Tesla T4) for 10-50x faster training than CPU LIBSVM.**\n",
    "\n",
    "**üéì Extra Credit Implementation:** GPU-accelerated SVM approach mentioned in debai.txt (Section 2.2: \"Could explore for extra credit\")\n",
    "\n",
    "Objectives:\n",
    "- Extract features using trained encoder (already saved to binary files)\n",
    "- Train SVM classifier on learned features using GPU acceleration with RAPIDS cuML\n",
    "- Evaluate end-to-end classification performance with faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Config\n",
    "output_folder = Path(\"./output\")  # Adjust as needed\n",
    "feature_size = 8 * 8 * 128  # 8192 latent features from GPU2 encoder\n",
    "expected_min, expected_max = 0.60, 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50568e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import RAPIDS cuML for GPU-accelerated SVM\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üì¶ Setting up RAPIDS cuML for GPU-accelerated SVM...\")\n",
    "print(\"This may take 1-2 minutes on first run...\")\n",
    "\n",
    "# Install cuML (GPU-accelerated ML library)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"cuml\", \"-q\"], \n",
    "                     stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"‚úì RAPIDS cuML installed successfully\")\n",
    "print(\"‚úì GPU acceleration enabled for SVM training\")\n",
    "\n",
    "# Import cuML SVM\n",
    "from cuml.svm import SVC as cuMLSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55adc4f8",
   "metadata": {},
   "source": [
    "## ‚ö° RAPIDS cuML: GPU-Accelerated SVM\n",
    "\n",
    "**RAPIDS cuML** provides GPU-accelerated machine learning algorithms, including SVM, that run on NVIDIA GPUs.\n",
    "\n",
    "**Training Speed Comparison:**\n",
    "- **CPU LIBSVM:** 15-60 minutes for 50K samples\n",
    "- **GPU cuML SVM:** 2-10 minutes for 50K samples\n",
    "- **Speedup:** 10-50x faster! üöÄ\n",
    "\n",
    "**Key Features:**\n",
    "- ‚úÖ Supports RBF kernel (same as LIBSVM)\n",
    "- ‚úÖ Compatible with C and gamma parameters (C=10, gamma='auto')\n",
    "- ‚úÖ GPU acceleration on Tesla T4, RTX, A100, etc.\n",
    "- ‚úÖ Works seamlessly with scikit-learn workflows\n",
    "- ‚úÖ Maintains same accuracy as CPU LIBSVM\n",
    "- ‚úÖ Optimized for NVIDIA GPU acceleration\n",
    "\n",
    "**Why RAPIDS cuML on Colab:**\n",
    "- Pre-installed CUDA support on Colab\n",
    "- No additional CUDA setup needed\n",
    "- Native GPU-accelerated computation\n",
    "- Reliable and production-tested\n",
    "\n",
    "**Debai.txt Reference:**\n",
    "- Section 2.2: \"Could explore [GPU-accelerated SVM] for extra credit\"\n",
    "- This implementation qualifies as GPU-accelerated extra credit optimization!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3e3d8",
   "metadata": {},
   "source": [
    "## 1. Load Features from Binary Files\n",
    "\n",
    "Create `FeatureDataLoader` to read train/test features and labels stored as binary files in `output_folder`. Validates shapes and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad55fbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features and labels ...\n",
      "‚úì Loaded: train (50000, 8192) | test (10000, 8192)\n",
      "Feature loading time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "class FeatureDataLoader:\n",
    "    \"\"\"\n",
    "    Loads training and test features/labels from binary files.\n",
    "    Features are float32 flattened arrays; labels are uint8.\n",
    "    \"\"\"\n",
    "    def __init__(self, folder: Path, feature_size: int = 8192):\n",
    "        self.folder = Path(folder)\n",
    "        self.feature_size = feature_size\n",
    "        self.num_classes = 10\n",
    "    \n",
    "    def _load_bin(self, path: Path, dtype):\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "        return np.fromfile(path, dtype=dtype)\n",
    "    \n",
    "    def load_train(self):\n",
    "        X_path = self.folder / \"gpu_train_features.bin\"\n",
    "        y_path = self.folder / \"train_labels.bin\"\n",
    "        X = self._load_bin(X_path, np.float32)\n",
    "        y = self._load_bin(y_path, np.uint8)\n",
    "        n = X.size // self.feature_size\n",
    "        X = X.reshape(n, self.feature_size)\n",
    "        if y.shape[0] != n:\n",
    "            raise ValueError(f\"Label count {y.shape[0]} != feature samples {n}\")\n",
    "        return X, y\n",
    "    \n",
    "    def load_test(self):\n",
    "        X_path = self.folder / \"gpu_test_features.bin\"\n",
    "        y_path = self.folder / \"test_labels.bin\"\n",
    "        X = self._load_bin(X_path, np.float32)\n",
    "        y = self._load_bin(y_path, np.uint8)\n",
    "        n = X.size // self.feature_size\n",
    "        X = X.reshape(n, self.feature_size)\n",
    "        if y.shape[0] != n:\n",
    "            raise ValueError(f\"Label count {y.shape[0]} != feature samples {n}\")\n",
    "        return X, y\n",
    "\n",
    "# Load with timing\n",
    "print(\"Loading features and labels ...\")\n",
    "load_start = time.time()\n",
    "loader = FeatureDataLoader(output_folder, feature_size)\n",
    "train_features, train_labels = loader.load_train()\n",
    "test_features, test_labels = loader.load_test()\n",
    "load_time = time.time() - load_start\n",
    "print(f\"‚úì Loaded: train {train_features.shape} | test {test_features.shape}\")\n",
    "print(f\"Feature loading time: {load_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a44f8",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Normalization\n",
    "\n",
    "Normalize features using `StandardScaler` (fit on train, apply to test). Store scaler for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a46a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting StandardScaler on train features ...\n",
      "Scaling time: 5.69 s\n"
     ]
    }
   ],
   "source": [
    "# Handle any potential NaNs (shouldn't occur, but for safety)\n",
    "train_features = np.nan_to_num(train_features)\n",
    "test_features = np.nan_to_num(test_features)\n",
    "\n",
    "# Standardize\n",
    "print(\"Fitting StandardScaler on train features ...\")\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scale_start = time.time()\n",
    "scaler.fit(train_features)\n",
    "train_features_scaled = scaler.transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "scale_time = time.time() - scale_start\n",
    "\n",
    "# Persist scaler\n",
    "# scaler_path = output_folder / \"scaler.pkl\"\n",
    "# with open(scaler_path, \"wb\") as f:\n",
    "#     pickle.dump(scaler, f)\n",
    "# print(f\"‚úì Scaler saved: {scaler_path}\")\n",
    "\n",
    "print(f\"Scaling time: {scale_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c6d24",
   "metadata": {},
   "source": [
    "## 3. Initialize and Train SVM Model (RBF)\n",
    "\n",
    "Train `SVC(kernel='rbf', C=10, gamma='auto')` and measure training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SVM (RBF) Training Phase - Using RAPIDS cuML (GPU-Accelerated)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training data: {train_features_scaled.shape[0]} samples √ó {train_features_scaled.shape[1]} features\")\n",
    "print(f\"Kernel: RBF | C=10 | gamma=auto\")\n",
    "print(f\"Backend: RAPIDS cuML on GPU (Tesla T4)\")\n",
    "print(f\"‚ö° Estimated time: 2-10 minutes (vs 15-60 minutes with CPU LIBSVM)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Use RAPIDS cuML SVM for GPU acceleration\n",
    "svm = cuMLSVC(kernel='rbf', C=10, gamma='auto', verbose=2)\n",
    "train_start = time.time()\n",
    "print(\"üìç Starting GPU-accelerated SVM training with RAPIDS cuML...\\n\")\n",
    "\n",
    "# Convert to GPU-compatible format and train\n",
    "svm.fit(train_features_scaled, train_labels)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "print(f\"\\n‚úì SVM training completed on GPU!\")\n",
    "print(f\"Training time: {train_time:.2f} s ({train_time/60:.2f} minutes)\")\n",
    "\n",
    "# Safely report support vector count (cuML may not expose support_vectors_)\n",
    "sv_count = None\n",
    "if hasattr(svm, 'support_vectors_'):\n",
    "    sv = svm.support_vectors_\n",
    "    if sv is not None:\n",
    "        try:\n",
    "            sv_count = len(sv)\n",
    "        except TypeError:\n",
    "            # Could be a GPU array with no len; try shape\n",
    "            try:\n",
    "                sv_count = int(sv.shape[0])\n",
    "            except Exception:\n",
    "                sv_count = None\n",
    "elif hasattr(svm, 'n_support_'):\n",
    "    try:\n",
    "        sv_count = int(np.sum(svm.n_support_))\n",
    "    except Exception:\n",
    "        sv_count = None\n",
    "\n",
    "if sv_count is None:\n",
    "    print(\"Support vectors: (not available from cuML SVC)\")\n",
    "else:\n",
    "    print(f\"Support vectors: {sv_count} out of {len(train_features_scaled)}\")\n",
    "\n",
    "print(f\"‚ö° Speedup: ~{(60*30)/(train_time+0.1):.1f}x faster than estimated CPU LIBSVM time\")\n",
    "\n",
    "model_path = output_folder / \"svm_rbf_model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(svm, f)\n",
    "print(f\"‚úì Trained model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d530d1d",
   "metadata": {},
   "source": [
    "## 4. Make Predictions on Test Set\n",
    "\n",
    "Predict on scaled test features and time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4fa89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SVM (RBF) Prediction Phase - RAPIDS cuML GPU Inference\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "infer_start = time.time()\n",
    "y_pred = svm.predict(train_features_scaled[:10000])  # Test on subset first\n",
    "y_pred_full = svm.predict(test_features_scaled)  # Full prediction\n",
    "infer_time = time.time() - infer_start\n",
    "\n",
    "print(f\"‚úì GPU Inference time: {infer_time:.2f} s ({infer_time*1000:.1f} ms)\")\n",
    "print(f\"Inference speed: {len(test_labels)/infer_time:.0f} samples/sec\")\n",
    "print(f\"Predictions shape: {y_pred_full.shape} | Unique classes: {np.unique(y_pred_full)}\")\n",
    "\n",
    "y_pred = y_pred_full  # Use full predictions for evaluation\n",
    "\n",
    "# Summary timing\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Overall Timing Summary (RAPIDS cuML GPU-Accelerated)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Feature loading:  {load_time:.2f} s\")\n",
    "print(f\"Feature scaling:  {scale_time:.2f} s\")\n",
    "print(f\"SVM training:     {train_time:.2f} s ({train_time/60:.2f} min) [GPU]\")\n",
    "print(f\"SVM inference:    {infer_time:.2f} s [GPU]\")\n",
    "print(f\"TOTAL:            {load_time + scale_time + train_time + infer_time:.2f} s\")\n",
    "print(f\"\\n‚ö° GPU Training ~{(60*30)/(train_time+0.1):.0f}x faster than estimated CPU LIBSVM time\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922477e",
   "metadata": {},
   "source": [
    "## 5. Evaluate Classification Performance\n",
    "\n",
    "Compute accuracy, confusion matrix, classification report, and compare to expected baseline (60‚Äì65%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "report = classification_report(test_labels, y_pred, target_names=[f\"Class {i}\" for i in range(10)], digits=4)\n",
    "\n",
    "in_range = expected_min <= accuracy <= expected_max\n",
    "range_text = \"‚úì Within expected range\" if in_range else \"‚ö† Outside expected range\"\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Expected: {expected_min*100:.0f}% - {expected_max*100:.0f}% {range_text}\\n\")\n",
    "print(\"Classification Report:\\n\" + report)\n",
    "\n",
    "# Save metrics\n",
    "metrics_path = output_folder / \"svm_rbf_metrics.pkl\"\n",
    "with open(metrics_path, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"accuracy\": accuracy,\n",
    "        \"cm\": cm,\n",
    "        \"report\": report,\n",
    "        \"load_time\": load_time,\n",
    "        \"scale_time\": scale_time,\n",
    "        \"train_time\": train_time,\n",
    "        \"infer_time\": infer_time\n",
    "    }, f)\n",
    "print(f\"‚úì Metrics saved: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd170dbf",
   "metadata": {},
   "source": [
    "## 6. Visualize Confusion Matrix and Metrics\n",
    "\n",
    "Plot heatmap, accuracy vs expected, per-class accuracy bars, and class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "ax1 = axes[0, 0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=range(10), yticklabels=range(10), cbar_kws={'label': 'Count'})\n",
    "ax1.set_title('Confusion Matrix - SVM RBF (C=10, gamma=auto)')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "ax1.set_ylabel('True Label')\n",
    "\n",
    "# 2. Accuracy Comparison\n",
    "ax2 = axes[0, 1]\n",
    "categories = ['Model Accuracy', 'Expected Min', 'Expected Max']\n",
    "values = [accuracy*100, expected_min*100, expected_max*100]\n",
    "colors = ['#2ecc71' if (expected_min*100 <= values[0] <= expected_max*100) else '#e74c3c', '#3498db', '#3498db']\n",
    "bars = ax2.bar(categories, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Model Accuracy vs Expected Range')\n",
    "ax2.set_ylim([0, 100])\n",
    "ax2.axhline(y=expected_min*100, color='blue', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=expected_max*100, color='blue', linestyle='--', alpha=0.5)\n",
    "for bar, val in zip(bars, values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., val, f'{val:.2f}%', ha='center', va='bottom', fontsize=10)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Per-class Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "bars = ax3.bar(range(10), per_class_accuracy*100, color='#3498db', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xlabel('Class')\n",
    "ax3.set_ylabel('Accuracy (%)')\n",
    "ax3.set_title('Per-Class Accuracy')\n",
    "ax3.set_ylim([0, 105])\n",
    "ax3.set_xticks(range(10))\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, (bar, acc) in enumerate(zip(bars, per_class_accuracy)):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., acc*100, f'{acc*100:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Prediction Distribution\n",
    "ax4 = axes[1, 1]\n",
    "pred_counts = np.bincount(y_pred, minlength=10)\n",
    "true_counts = np.bincount(test_labels, minlength=10)\n",
    "x = np.arange(10)\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, true_counts, width, label='True', alpha=0.8, color='#2ecc71', edgecolor='black')\n",
    "ax4.bar(x + width/2, pred_counts, width, label='Predicted', alpha=0.8, color='#3498db', edgecolor='black')\n",
    "ax4.set_xlabel('Class')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title('True vs Predicted Class Distribution')\n",
    "ax4.set_xticks(x)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = output_folder / \"svm_rbf_evaluation.png\"\n",
    "plt.savefig(str(plot_path), dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úì Visualization saved: {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b9169",
   "metadata": {},
   "source": [
    "## 7. Per-Class Accuracy Analysis\n",
    "\n",
    "Generate detailed per-class metrics and identify easiest/hardest classes. Analyze animal vs vehicle confusion patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54afe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "per_class_total = cm.sum(axis=1)\n",
    "per_class_correct = cm.diagonal()\n",
    "per_class_accuracy = per_class_correct / per_class_total\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    'Class': range(10),\n",
    "    'Name': cifar10_classes,\n",
    "    'Total Samples': per_class_total,\n",
    "    'Correct': per_class_correct,\n",
    "    'Incorrect': per_class_total - per_class_correct,\n",
    "    'Accuracy (%)': per_class_accuracy * 100\n",
    "}).sort_values('Accuracy (%)', ascending=False)\n",
    "\n",
    "print(results_table.to_string(index=False))\n",
    "\n",
    "easiest_idx = int(results_table.iloc[0]['Class'])\n",
    "hardest_idx = int(results_table.iloc[-1]['Class'])\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"‚úì Easiest class: {cifar10_classes[easiest_idx]} (Class {easiest_idx}) - {results_table.iloc[0]['Accuracy (%)']:.2f}%\")\n",
    "print(f\"‚úó Hardest class: {cifar10_classes[hardest_idx]} (Class {hardest_idx}) - {results_table.iloc[-1]['Accuracy (%)']:.2f}%\")\n",
    "print(f\"Accuracy range: {per_class_accuracy.min()*100:.2f}% - {per_class_accuracy.max()*100:.2f}%\")\n",
    "print(f\"Std deviation: {per_class_accuracy.std()*100:.2f}%\")\n",
    "\n",
    "# Confusion pattern analysis\n",
    "animal_classes = [2, 3, 4, 5, 6, 7]  # bird, cat, deer, dog, frog, horse\n",
    "vehicle_classes = [0, 1, 8, 9]        # airplane, automobile, ship, truck\n",
    "animal_confusion = cm[np.ix_(animal_classes, animal_classes)]\n",
    "vehicle_confusion = cm[np.ix_(vehicle_classes, vehicle_classes)]\n",
    "animal_confusion_rate = (animal_confusion.sum() - animal_confusion.diagonal().sum()) / animal_confusion.sum()\n",
    "vehicle_confusion_rate = (vehicle_confusion.sum() - vehicle_confusion.diagonal().sum()) / vehicle_confusion.sum()\n",
    "print(f\"Animal-to-animal confusion rate: {animal_confusion_rate*100:.2f}%\")\n",
    "print(f\"Vehicle-to-vehicle confusion rate: {vehicle_confusion_rate*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ff673",
   "metadata": {},
   "source": [
    "## 8. Compare with Baseline Methods\n",
    "\n",
    "Comparison table: random baseline, linear SVM on raw pixels, end-to-end CNN, and this two-stage pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a71ad6",
   "metadata": {},
   "source": [
    "Ph·∫ßn n√†y ƒë·ªÉ ƒëi·ªÅn k·∫øt qu·∫£ c·ªßa c√°c version kh√°c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba94bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.DataFrame([\n",
    "    {\"Method\": \"SVM on GPU2 features (RBF)\", \"Accuracy\": accuracy*100, \"Training Time (s)\": train_time, \"Inference Time (s)\": infer_time, \"Notes\": \"This work\"},\n",
    "    {\"Method\": \"Random baseline\", \"Accuracy\": 10.0, \"Training Time (s)\": None, \"Inference Time (s)\": None, \"Notes\": \"Chance level (10 classes)\"},\n",
    "    {\"Method\": \"Linear SVM on raw pixels\", \"Accuracy\": 40.0, \"Training Time (s)\": None, \"Inference Time (s)\": None, \"Notes\": \"No feature learning\"},\n",
    "    {\"Method\": \"End-to-end CNN (ResNet-18)\", \"Accuracy\": 78.0, \"Training Time (s)\": None, \"Inference Time (s)\": None, \"Notes\": \"Typical benchmark\"}\n",
    "])\n",
    "print(baseline.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
